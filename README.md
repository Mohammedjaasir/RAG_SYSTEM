<div align="center">

# ğŸ§¾ Receipt RAG Extraction System

**AI-powered receipt data extraction with zero hallucinations and structured JSON output**

[![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-1.1.0-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![LangChain](https://img.shields.io/badge/LangChain-RAG-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white)](https://langchain.com/)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-VectorDB-F66B2B?style=for-the-badge)](https://www.trychroma.com/)
[![Phi-3](https://img.shields.io/badge/LLM-Phi--3-FF5733?style=for-the-badge&logo=microsoft&logoColor=white)](https://azure.microsoft.com/en-us/products/phi-3)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)

<br />

> Transform raw, messy OCR receipt text into clean, validated, structured JSON data â€” powered by Retrieval-Augmented Generation, multi-prompt LLM strategies, and adaptive pattern learning.

</div>

---

## âœ¨ Features

| Feature | Description |
|---|---|
| ğŸ¤– **Multi-Prompt LLM Strategy** | Separate, specialized prompts for header fields (vendor, date, total) and itemized line extraction for maximum precision |
| ğŸ” **RAG-Augmented Extraction** | Retrieves semantically similar receipt patterns from ChromaDB to guide the LLM with live-context examples |
| ğŸ”¤ **OCR Normalization** | Auto-corrects common OCR errors (scrambled layouts, garbled characters) before LLM processing |
| ğŸ·ï¸ **Vendor Classification** | Identifies and classifies vendor/shop types (restaurant, hotel, supermarket, etc.) to apply domain-specific extraction rules |
| ğŸ›¡ï¸ **Hallucination Guard** | Validates LLM output against raw OCR source â€” any field not supported by the original text is flagged or rejected |
| ğŸ“Š **Confidence Scoring** | Per-field confidence scores and an overall validation flag for downstream quality control |
| ğŸ§  **Adaptive Pattern Learning** | Automatically learns new receipt formats/layouts and stores them in the knowledge base to improve future extractions |
| âš¡ **FastAPI REST Interface** | Production-ready API with `/extract`, `/health`, and `/clean-db` endpoints with full CORS support |
| ğŸ—ƒï¸ **Structured JSON Output** | Outputs a clean, validated JSON schema with vendor info, date, currency, line items, totals, VAT, and more |

---

## ğŸ—ï¸ Architecture

```
Receipt Image / OCR Text
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OCR Client      â”‚  â† Tesseract / Google Vision / Custom OCR
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ raw text
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OCR Normalizer   â”‚  â† Corrects scrambled layouts, encodes errors
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ cleaned text
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vendor Classifier â”‚â”€â”€â”€â”€â–¶â”‚  RAG Retriever      â”‚
â”‚                   â”‚     â”‚  (ChromaDB +        â”‚
â”‚ (type, name)      â”‚     â”‚   LangChain)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚ top-k context examples
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Phi-3 LLM Engine  â”‚  â† Multi-Prompt Strategy
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â€¢ Prompt 1: Header fields
        â”‚  â”‚ Header Promptâ”‚  â”‚     â€¢ Prompt 2: Line items
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ Items Prompt â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ raw LLM response
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Hallucination      â”‚  â† Validates every field vs. OCR
        â”‚ Validator          â”‚    Rejects unsupported data
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Confidence Scorer â”‚  â† Per-field scores + overall flag
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
             JSON Output
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|---|---|
| **Language** | Python 3.9+ |
| **LLM** | Microsoft Phi-3 (via Ollama or HuggingFace) |
| **RAG Framework** | LangChain + LangChain-Community |
| **Vector Database** | ChromaDB |
| **Embeddings** | Sentence-Transformers |
| **API Framework** | FastAPI + Uvicorn |
| **OCR** | Tesseract, Google Vision, or custom client |
| **PDF Support** | PyMuPDF |
| **Validation** | Pydantic v2 |
| **JSON Repair** | json-repair |

---

## ğŸ“‚ Project Structure

```
RAG_SYSTEM/
â”œâ”€â”€ receipt/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline_orchestrator.py      # Main entry point: full end-to-end pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                          # Core RAG logic
â”‚   â”‚   â”œâ”€â”€ receipt_rag.py            #   RAG pipeline, LLM prompting, extraction
â”‚   â”‚   â”œâ”€â”€ rag_retriever.py          #   ChromaDB retrieval logic
â”‚   â”‚   â”œâ”€â”€ vector_store.py           #   Vector store management
â”‚   â”‚   â”œâ”€â”€ knowledge_base_loader.py  #   Loads receipt patterns into ChromaDB
â”‚   â”‚   â”œâ”€â”€ pattern_learner.py        #   Adaptive pattern learning
â”‚   â”‚   â”œâ”€â”€ vendor_classifier.py      #   Receipt type/vendor classification
â”‚   â”‚   â”œâ”€â”€ ocr_client.py             #   OCR integration (multi-engine)
â”‚   â”‚   â”œâ”€â”€ rag_refresh_manager.py    #   DB refresh/rebuild management
â”‚   â”‚   â”œâ”€â”€ logger_utils.py           #   Logging utilities
â”‚   â”‚   â””â”€â”€ main.py                   #   FastAPI app & endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/                   # LLM extraction modules
â”‚   â”‚   â”œâ”€â”€ phi_item_extractor.py     #   Phi-3 line item extraction
â”‚   â”‚   â”œâ”€â”€ phi_hf_loader.py          #   HuggingFace Phi-3 model loader
â”‚   â”‚   â”œâ”€â”€ comprehensive_receipt_extractor.py
â”‚   â”‚   â”œâ”€â”€ improved_vat_extractor.py
â”‚   â”‚   â””â”€â”€ additional_fields_extractor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ classification/               # Vendor/receipt classification
â”‚   â”œâ”€â”€ standardization/              # Field normalization & standardization
â”‚   â”œâ”€â”€ reconstruction/               # Data reconstruction utilities
â”‚   â”œâ”€â”€ orchestration/                # Orchestration helpers
â”‚   â””â”€â”€ pipeline/                     # Pipeline stage definitions
â”‚
â”œâ”€â”€ config/                           # App / model configuration
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.9 or higher
- [Ollama](https://ollama.com/) installed locally (for Phi-3 via Ollama)
- *(Optional)* HuggingFace account for model downloads

### 1. Clone the Repository

```bash
git clone https://github.com/Mohammedjaasir/RAG_SYSTEM.git
cd RAG_SYSTEM
```

### 2. Create & Activate Virtual Environment

```bash
# Create virtual environment
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate

# Activate (macOS / Linux)
source .venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Pull the Phi-3 Model (Ollama)

```bash
ollama pull phi3
```

> **Note:** If using HuggingFace instead, set the appropriate model environment variables in your `.env` file.

### 5. Environment Configuration (Optional)

Create a `.env` file in the root directory:

```env
# LLM Backend: "ollama" or "huggingface"
LLM_BACKEND=ollama

# Ollama settings
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=phi3

# ChromaDB path
CHROMA_DB_PATH=./receipt/rag/chroma_db
```

---

## ğŸš€ Running the API

Start the FastAPI server:

```bash
uvicorn receipt.rag.main:app --host 0.0.0.0 --port 8000 --reload
```

The API will be live at **`http://localhost:8000`**

ğŸ“– Interactive API docs: **`http://localhost:8000/docs`**

---

## ğŸ“¡ API Endpoints

### `POST /extract` â€” Extract Receipt Data

Send raw OCR text and receive structured JSON.

**Request Body:**
```json
{
  "ocr_text": "SOCIAL KITCHEN\n123 High Street\nDate: 12/05/2024\nCappuccino       3.50\nAvocado Toast    8.00\nOrange Juice     4.20\n-------------------\nSubTotal:       15.70\nVAT (20%):       3.14\nTOTAL:          18.84",
  "retrieve_k": 3
}
```

**Response:**
```json
{
  "vendor_name": "Social Kitchen",
  "vendor_type": "restaurant",
  "date": "2024-05-12",
  "currency": "GBP",
  "items": [
    { "name": "Cappuccino",     "quantity": 1, "unit_price": 3.50,  "total_price": 3.50  },
    { "name": "Avocado Toast",  "quantity": 1, "unit_price": 8.00,  "total_price": 8.00  },
    { "name": "Orange Juice",   "quantity": 1, "unit_price": 4.20,  "total_price": 4.20  }
  ],
  "subtotal": 15.70,
  "vat": 3.14,
  "total": 18.84,
  "validation_passed": true,
  "_metadata": {
    "overall_confidence": 0.97,
    "relevance_scores": [0.91, 0.87, 0.82]
  }
}
```

---

### `GET /health` â€” Health Check

```bash
curl http://localhost:8000/health
```

```json
{
  "status": "healthy",
  "service": "receipt-rag-api",
  "version": "1.1.0"
}
```

---

### `POST /clean-db` â€” Reset Vector Database

Forces the ChromaDB vector store to clear and rebuild on the next request. Useful when significantly updating the knowledge base.

```bash
curl -X POST http://localhost:8000/clean-db
```

---

## ğŸ§ª Testing

Run individual test scripts from the `receipt/rag/` directory:

```bash
# Test RAG extraction end-to-end
python receipt/rag/test_rag_demo.py

# Test diverse receipt types (hotel, restaurant, supermarket)
python receipt/rag/test_diverse.py

# Test hallucination prevention
python receipt/rag/test_hallucination_fix.py

# Test shop/vendor name extraction accuracy
python receipt/rag/test_shop_name.py

# Test API endpoints directly
python receipt/rag/test_api.py
```

---

## ğŸ”„ How It Works

### 1. ğŸ“¥ Input & Normalization
Raw OCR text (from any OCR engine) is fed into the normalizer, which corrects common OCR artifacts: character substitutions, scrambled column layouts (numbers appearing before item names), encoding issues, and whitespace noise.

### 2. ğŸ·ï¸ Vendor Classification
The system detects the vendor name and type (restaurant, hotel, supermarket, pharmacy, etc.) using pattern-matching and a classifier trained on receipt structures. This determination selects the appropriate extraction rules.

### 3. ğŸ” RAG Context Retrieval
The normalized text is embedded with `sentence-transformers` and queried against ChromaDB. The top-k most semantically similar reference receipts are retrieved and injected as in-context examples to the LLM.

### 4. ğŸ¤– Multi-Prompt LLM Extraction  
Two specialized LLM prompts run sequentially:
- **Header Prompt** â€“ extracts vendor name, date, address, totals, VAT, and currency.
- **Item Prompt** â€“ extracts each line item with quantity, unit price, and total.

This separation reduces cross-contamination errors and improves accuracy on complex receipts.

### 5. ğŸ›¡ï¸ Hallucination Validation
Every extracted field is validated against the source OCR text. Fields containing values not grounded in the original text are flagged as low-confidence or rejected entirely.

### 6. ğŸ“Š Confidence Scoring & Output
Each field receives a confidence score. An `overall_confidence` and `validation_passed` flag are returned alongside the extracted data.

### 7. ğŸ§  Pattern Learning
Successfully extracted receipts are automatically stored back into the ChromaDB knowledge base, continuously improving retrieval quality for future receipts of similar formats.

---

## ğŸ—ºï¸ Roadmap

- [ ] ğŸ“¸ Direct image input support (auto-OCR from image uploads)
- [ ] ğŸŒ Multi-language receipt support
- [ ] ğŸ” API key authentication for production deployments
- [ ] ğŸ“ˆ Extraction analytics dashboard
- [ ] ğŸ—„ï¸ PostgreSQL / cloud database integration
- [ ] ğŸ³ Docker Compose deployment setup

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to your branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

<div align="center">

Made with â¤ï¸ by [Mohammedjaasir](https://github.com/Mohammedjaasir)

â­ **Star this repo** if you find it useful!

</div>
